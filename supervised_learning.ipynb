{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import seq_helper as seqh\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.cm import spectral\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with_N = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "dirname = ''.join(['./pre_process_dataset/'])\n",
    "file_list = []\n",
    "fm_set = set()\n",
    "Q_set = set()\n",
    "label = []\n",
    "\n",
    "name_image_dict = {}\n",
    "for name in os.listdir(dirname):    \n",
    "    file_path_name = ''.join(['./pre_process_dataset/',name])    \n",
    "    data = (seqh.read_from_file(file_path_name))   \n",
    "    \n",
    "    Q_hist = set(data[0].keys())        \n",
    "    Q_set.update(Q_hist)    \n",
    "        \n",
    "    fm_hist = data[1]\n",
    "    \n",
    "    if not with_N:\n",
    "        # collect what to remove    \n",
    "        fm_to_remove = []\n",
    "        for fm in fm_hist.keys():\n",
    "            if 'N' in fm:\n",
    "                fm_to_remove.append(fm)\n",
    "\n",
    "        # remove it\n",
    "        for i in fm_to_remove:\n",
    "            fm_hist.pop(i, None)\n",
    "           \n",
    "    # collect unique\n",
    "    fm_set.update(set(fm_hist.keys()))\n",
    "\n",
    "    label.append(float(data[2]))\n",
    "    \n",
    "    file_list.append(data)\n",
    "\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# format data into matrix\n",
    "data_num = len(file_list)\n",
    "\n",
    "Q_dim = len(Q_set)\n",
    "Q_index = [i for i in range(Q_dim)]\n",
    "Q_name = list(Q_set)\n",
    "Q_name_index_dict = dict(zip(Q_name, Q_index))\n",
    "\n",
    "fm_dim = len(fm_set)\n",
    "fm_index = [i for i in range(fm_dim)]  #for the dict to matrix mapping\n",
    "fm_name = list(fm_set)\n",
    "fm_name_index_dict = dict(zip(fm_name, fm_index))\n",
    "\n",
    "Q = np.zeros((data_num, Q_dim))    #Q quality matrix, shape num_data, dim\n",
    "F = np.zeros((data_num, fm_dim))   #4-mer matrix, shape num_data, dim\n",
    "\n",
    "for i in range(data_num):\n",
    "    data = file_list[i]\n",
    "    Q_hist = data[0]\n",
    "    fm_hist = data[1]\n",
    "    data_Q_num = np.sum(np.array(list(Q_hist.values())))\n",
    "    data_fm_num = np.sum(np.array(list(fm_hist.values())))    \n",
    "    \n",
    "    for key, value in Q_hist.items():\n",
    "        j = Q_name_index_dict[key]\n",
    "        Q[i,j] = value/data_Q_num       #normalization\n",
    "        \n",
    "    for key, value in fm_hist.items():\n",
    "        j = fm_name_index_dict[key]\n",
    "        F[i,j] = value/data_fm_num      #normalization\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read fragment file\n",
    "import numpy as np\n",
    "tmpData = np.genfromtxt('matrix_data/fragLenOutput.txt',delimiter='\\t',dtype=float)\n",
    "\n",
    "#length file\n",
    "L = np.delete(tmpData,0,1)\n",
    "for i in range(0,len(L)):\n",
    "    curSum = np.sum(L[i])\n",
    "    for j in range(0,len(L[i])):\n",
    "        tmp = float(L[i][j]) / float(curSum)\n",
    "        L[i][j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation set using quality score\n",
      "\n",
      "accuracy:  0.888888888889\n",
      "precision:  0.909090909091\n",
      "recall:  0.857142857143\n",
      "[[30  5]\n",
      " [ 3 34]]\n"
     ]
    }
   ],
   "source": [
    "#Q is quality file\n",
    "#F is 4-mer file\n",
    "#L is fragment length file\n",
    "# logistic regression, 0.6 training, 0.2 validation, 0.2 testing\n",
    "Q_train, Q_test, F_train, F_test, L_train, L_test, label_train, label_test = \\\n",
    "    train_test_split(Q,F,L,label,test_size=0.4, random_state=42)\n",
    "    \n",
    "Q_valid, Q_test, F_valid, F_test, L_valid, L_test, label_valid, label_test = \\\n",
    "    train_test_split(Q_test,F_test,L_test, label_test,test_size=0.5, random_state=42)\n",
    "\n",
    "C = 100000000000 # large C -> no regularization\n",
    "logistic_regr = LogisticRegression(penalty='l2', C=C) \n",
    "\n",
    "val_pred_list = []\n",
    "logistic_regr.fit(Q_train, label_train)\n",
    "\n",
    "#Quality score\n",
    "# on validation set    \n",
    "valid_pred = (logistic_regr.predict(Q_valid))\n",
    "valid_pred_l = list((valid_pred.astype('float')).astype('int'))\n",
    "label_valid_l = list((label_valid.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on validation set using quality score\\n\")\n",
    "seqh.evaluate_result(label_valid_l, valid_pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set using quality score\n",
      "\n",
      "accuracy:  0.791666666667\n",
      "precision:  0.775\n",
      "recall:  0.837837837838\n",
      "[[31  6]\n",
      " [ 9 26]]\n",
      "(72, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# on test set    \n",
    "test_pred = (logistic_regr.predict(Q_test))\n",
    "test_pred_l = list((test_pred.astype('float')).astype('int'))\n",
    "label_test_l = list((label_test.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on test set using quality score\\n\")\n",
    "\n",
    "seqh.evaluate_result(label_test_l, test_pred_l)\n",
    "\n",
    "a=logistic_regr.predict_proba(Q_test)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation set using 4-mer\n",
      "\n",
      "accuracy:  0.944444444444\n",
      "precision:  0.969696969697\n",
      "recall:  0.914285714286\n",
      "[[32  3]\n",
      " [ 1 36]]\n"
     ]
    }
   ],
   "source": [
    "C = 100000000000 # large C -> no regularization\n",
    "logistic_regr = LogisticRegression(penalty='l2', C=C) \n",
    "\n",
    "val_pred_list = []\n",
    "logistic_regr.fit(F_train, label_train)\n",
    "\n",
    "# 4-mer\n",
    "# on validation set    \n",
    "valid_pred = (logistic_regr.predict(F_valid))\n",
    "valid_pred_l = list((valid_pred.astype('float')).astype('int'))\n",
    "label_valid_l = list((label_valid.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on validation set using 4-mer\\n\")\n",
    "\n",
    "seqh.evaluate_result(label_valid_l, valid_pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation set using 4-mer score\n",
      "\n",
      "accuracy:  0.958333333333\n",
      "precision:  1.0\n",
      "recall:  0.918918918919\n",
      "[[34  3]\n",
      " [ 0 35]]\n"
     ]
    }
   ],
   "source": [
    "# 4-mer\n",
    "# on test set    \n",
    "test_pred = (logistic_regr.predict(F_test))\n",
    "test_pred_l = list((test_pred.astype('float')).astype('int'))\n",
    "label_test_l = list((label_test.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on validation set using 4-mer score\\n\")\n",
    "\n",
    "seqh.evaluate_result(label_test_l, test_pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation set using fragment length\n",
      "\n",
      "accuracy:  0.930555555556\n",
      "precision:  0.941176470588\n",
      "recall:  0.914285714286\n",
      "[[32  3]\n",
      " [ 2 35]]\n"
     ]
    }
   ],
   "source": [
    "C = 100000000000 # large C -> no regularization\n",
    "logistic_regr = LogisticRegression(penalty='l2', C=C) \n",
    "\n",
    "val_pred_list = []\n",
    "logistic_regr.fit(L_train, label_train)\n",
    "\n",
    "# fragment length\n",
    "# on validation set    \n",
    "valid_pred = (logistic_regr.predict(L_valid))\n",
    "valid_pred_l = list((valid_pred.astype('float')).astype('int'))\n",
    "label_valid_l = list((label_valid.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on validation set using fragment length\\n\")\n",
    "\n",
    "seqh.evaluate_result(label_valid_l, valid_pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set using 4-mer score\n",
      "\n",
      "accuracy:  0.833333333333\n",
      "precision:  0.931034482759\n",
      "recall:  0.72972972973\n",
      "[[27 10]\n",
      " [ 2 33]]\n"
     ]
    }
   ],
   "source": [
    "# fragment length\n",
    "# on test set    \n",
    "test_pred = (logistic_regr.predict(L_test))\n",
    "test_pred_l = list((test_pred.astype('float')).astype('int'))\n",
    "label_test_l = list((label_test.astype('float')).astype('int'))\n",
    "\n",
    "print(\"Results on test set using 4-mer score\\n\")\n",
    "\n",
    "seqh.evaluate_result(label_test_l, test_pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.81964003e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.81964003e-05]\n",
      " [  8.04641294e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.04641294e-05]\n",
      " [  2.65231198e-04   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   2.65231198e-04]\n",
      " ..., \n",
      " [  5.12851652e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   5.12851652e-05]\n",
      " [  8.83753140e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.83753140e-05]\n",
      " [  8.86430201e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.86430201e-05]]\n",
      "[[  2.22070371e-01   2.19790801e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.81964003e-05]\n",
      " [  1.97335408e-01   1.75812534e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.04641294e-05]\n",
      " [  2.08401273e-01   2.40086573e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   2.65231198e-04]\n",
      " ..., \n",
      " [  2.10360493e-01   1.99504508e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   5.12851652e-05]\n",
      " [  2.00526007e-01   2.17504731e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.83753140e-05]\n",
      " [  1.61027912e-01   2.59176419e-02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.86430201e-05]]\n"
     ]
    }
   ],
   "source": [
    "#concatenate all of the features together\n",
    "tmpA = np.concatenate((Q,L),axis=1)\n",
    "print(L)\n",
    "print(tmpA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "if with_N:\n",
    "    F_name = 'F_with_N.csv'\n",
    "else:\n",
    "    F_name = 'F.csv'\n",
    "Q_name = 'Q.csv'\n",
    "L_name = 'L.csv'\n",
    "F_save = ''.join(['./matrix_data/', F_name])\n",
    "np.savetxt(F_save, F, delimiter=\",\")\n",
    "Q_save = ''.join(['./matrix_data/', Q_name])\n",
    "np.savetxt(Q_save, Q, delimiter=\",\")\n",
    "L_save = ''.join(['./matrix_data/', L_name])\n",
    "L = np.array(label).astype(np.float)\n",
    "np.savetxt(L_save, L, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
